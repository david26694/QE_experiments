{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:16.108052Z",
     "start_time": "2020-06-24T07:40:16.089502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.017287Z",
     "start_time": "2020-06-24T07:40:16.112132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidmasip/opt/anaconda3/envs/sk-experiments/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "from category_encoders.utils import TransformerWithTargetMixin\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sktools\n",
    "\n",
    "from sktools import QuantileEncoder\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.028058Z",
     "start_time": "2020-06-24T07:40:18.020347Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    '''\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        #print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        #print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "def elapsed_time_mins (time1,time2):\n",
    "    elapsed = np.round(np.abs(time1-time2)/60,decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "class SummaryEncoder(BaseEstimator, TransformerWithTargetMixin):\n",
    "\n",
    "    def __init__(self, cols, quantiles, m=1.):\n",
    "\n",
    "        self.cols = cols\n",
    "        self.quantiles = quantiles\n",
    "        self.m = m\n",
    "        self.encoder_list = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X = X.copy()\n",
    "        \n",
    "        for quantile in self.quantiles:\n",
    "            for col in self.cols:\n",
    "                percentile = round(quantile * 100)\n",
    "                X[f'{col}_{percentile}'] = X[col]\n",
    "\n",
    "        encoder_list = []\n",
    "        for quantile in self.quantiles:\n",
    "            col_names = []\n",
    "            for col in self.cols:\n",
    "                percentile = round(quantile * 100)\n",
    "                col_names.append(f'{col}_{percentile}')\n",
    "            enc = QuantileEncoder(\n",
    "                cols=col_names, quantile=quantile, m=self.m\n",
    "            )\n",
    "            enc.fit(X, y)\n",
    "            encoder_list.append(enc)\n",
    "\n",
    "        self.encoder_list = encoder_list\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_encoded = X.copy()\n",
    "        \n",
    "        for quantile in self.quantiles:\n",
    "            for col in self.cols:\n",
    "                percentile = round(quantile * 100)\n",
    "                X_encoded[f'{col}_{percentile}'] = X_encoded[col]\n",
    "\n",
    "        for encoder in self.encoder_list:\n",
    "            X_encoded = encoder.transform(X_encoded)\n",
    "        return X_encoded\n",
    "\n",
    "\n",
    "\n",
    "def fit_pipe(pipe,pipe_grid,X,y,subsample=False,n_max=20_000,best_params=True):\n",
    "    \n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "    \n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(pipe, param_grid=pipe_grid, n_jobs = -1, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    pipe_cv.fit(X,y)\n",
    "    \n",
    "    best_estimator = pipe_cv.best_estimator_.fit( X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "    \n",
    "    return best_estimator,grid_results,pipe_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:11.521898Z",
     "start_time": "2020-06-11T08:02:08.959333Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/stackoverflow.csv')\n",
    "\n",
    "d.ConvertedSalary = pd.to_numeric(d.ConvertedSalary,errors='coerce')\n",
    "\n",
    "d = d[d.ConvertedSalary.isna()!=True]\n",
    "\n",
    "\n",
    "\n",
    "d.to_csv('data/stackoverflow_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.042133Z",
     "start_time": "2020-06-24T07:40:18.030927Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    'data/house_kaggle.csv',\n",
    "    'data/stackoverflow.csv',\n",
    "    'data/ks.csv',\n",
    "    'data/medical_payments_sample.csv',\n",
    "    'data/cauchy.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.063271Z",
     "start_time": "2020-06-24T07:40:18.050527Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    ['Id','BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2','BsmtFinSF2', 'BsmtUnfSF','LowQualFinSF','FullBath','HalfBath'],\n",
    "    ['Respondent','Salary'],\n",
    "    [],\n",
    "    ['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name','Number_of_Payments_Included_in_Total_Amount'],\n",
    "    []\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.076256Z",
     "start_time": "2020-06-24T07:40:18.069306Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    ['MSSubClass','MSZoning','LotShape','LandContour','Utilities','LotConfig','Neighborhood','BldgType','HouseStyle','YearBuilt','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','MasVnrType','Heating','HeatingQC'],\n",
    "    ['Country','Employment','FormalEducation','UndergradMajor','CompanySize','DevType','YearsCoding','LanguageWorkedWith','LanguageDesireNextYear','RaceEthnicity'],\n",
    "    ['category', 'main_category', 'currency','state','country'],\n",
    "    \n",
    "    ['Recipient_City', 'Recipient_State', 'Recipient_Zip_Code','Recipient_Country', 'Physician_Primary_Type',\n",
    "       'Physician_License_State_code1',\n",
    "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "       'Form_of_Payment_or_Transfer_of_Value','Nature_of_Payment_or_Transfer_of_Value'],\n",
    "    \n",
    "    ['value_1', 'value_2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.087861Z",
     "start_time": "2020-06-24T07:40:18.080974Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    ['SalePrice'],\n",
    "    ['ConvertedSalary'],\n",
    "    ['goal'],\n",
    "    ['Total_Amount_of_Payment_USDollars'],\n",
    "    ['target']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.100327Z",
     "start_time": "2020-06-24T07:40:18.093301Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = -1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic=time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns =['NameDataset',\n",
    "          # Scores\n",
    "          'enet_te_train_mae','enet_te_test_mae',\n",
    "          'enet_te_train_mse','enet_te_test_mse',\n",
    "          \n",
    "          'enet_pe_train_mae','enet_pe_test_mae',\n",
    "          'enet_pe_train_mse','enet_pe_test_mse',\n",
    "          \n",
    "          'xgb_te_train_mae','xgb_te_test_mae',\n",
    "          'xgb_te_train_mse','xgb_te_test_mse',\n",
    "          \n",
    "          'xgb_pe_train_mae','xgb_pe_test_mae',\n",
    "          'xgb_pe_train_mse','xgb_pe_test_mse',\n",
    "          \n",
    "          \n",
    "          'size',\n",
    "          \n",
    "          # Params\n",
    "          'enet_te_best_params','enet_pe_best_params',\n",
    "          # Time\n",
    "          'time_train_m']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:19.910962Z",
     "start_time": "2020-06-24T07:40:18.104900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------+\n",
      "| Data   | Model   | Train   | Test   |\n",
      "|--------+---------+---------+--------|\n",
      "+--------+---------+---------+--------+\n",
      "(1460, 69)\n",
      "+-------+---------+---------+---------+\n",
      "| house | enet_te | 18726.2 | 22824.3 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+-------+\n",
      "| house | enet_pe | 18538.1 | 23154 |\n",
      "+-------+---------+---------+-------+\n",
      "+-------+---------+---------+---------+\n",
      "| house | xgbs_te | 5417.03 | 19809.7 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| house | xgbs_pe | 5264.24 | 19525.6 |\n",
      "+-------+---------+---------+---------+\n",
      "(47702, 127)\n",
      "+-------+---------+---------+---------+\n",
      "| stack | enet_te | 55486.6 | 79632.3 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| stack | enet_pe | 49367.7 | 71283.5 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| stack | xgbs_te | 35147.1 | 70684.5 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| stack | xgbs_pe | 32596.4 | 74724.9 |\n",
      "+-------+---------+---------+---------+\n",
      "(100000, 8)\n",
      "+-------+---------+---------+---------+\n",
      "| ks.cs | enet_te | 67231.8 | 64391.9 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| ks.cs | enet_pe | 64801.9 | 62153.9 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| ks.cs | xgbs_te | 67171.5 | 72421.6 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+-------+---------+\n",
      "| ks.cs | xgbs_pe | 68588 | 69402.7 |\n",
      "+-------+---------+-------+---------+\n",
      "(100000, 11)\n",
      "+-------+---------+---------+---------+\n",
      "| medic | enet_te | 635.316 | 586.265 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| medic | enet_pe | 441.031 | 398.807 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+--------+---------+\n",
      "| medic | xgbs_te | 298.82 | 330.871 |\n",
      "+-------+---------+--------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| medic | xgbs_pe | 289.128 | 358.013 |\n",
      "+-------+---------+---------+---------+\n",
      "(100000, 3)\n",
      "+-------+---------+---------+---------+\n",
      "| cauch | enet_te | 23.7908 | 20.2556 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| cauch | enet_pe | 20.9082 | 17.3525 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| cauch | xgbs_te | 25.7001 | 22.1712 |\n",
      "+-------+---------+---------+---------+\n",
      "+-------+---------+---------+---------+\n",
      "| cauch | xgbs_pe | 25.6614 | 22.1329 |\n",
      "+-------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(tabulate(tabular_data=[], headers=['Data', 'Model', 'Train', 'Test'], tablefmt=\"psql\"))\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    if df.shape[0] > 100_000:\n",
    "        df = df.sample(n=100_000)\n",
    "\n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=drop[i])\n",
    "    \n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(df.drop(columns=target[i]), df[target[i]])\n",
    "   \n",
    "\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    enet_te,enet_te_grid_results,enet_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "    \n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'enet_te', score_enet_te_train, score_enet_te_test]], tablefmt='psql'))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = SummaryEncoder(cols= cols_enc[i],quantiles=[.25, .50, .75])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    enet_pe,enet_pe_grid_results,enet_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'enet_pe', score_enet_pe_train,score_enet_pe_test]], tablefmt='psql'))\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # xgb + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    xgb_te,xgb_te_grid_results,xgb_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'xgbs_te ', score_xgb_te_train,score_xgb_te_test]], tablefmt='psql'))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    # xgb + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    pe = SummaryEncoder(cols= cols_enc[i],quantiles=[.25, .50, .75])\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    xgb_pe,xgb_pe_grid_results,xgb_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    print(tabulate(tabular_data=[[data[i][5:10], 'xgbs_pe', score_xgb_pe_train,score_xgb_pe_test]], tablefmt='psql'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_pe_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgb_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgbt_pe_grid_results',data[i][5:10]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add Results\n",
    "    resultados.append([data[i].split('/')[1],\n",
    "                       #Scores\n",
    "                       score_enet_te_train,score_enet_te_test,\n",
    "                       score_enet_te_train_mse,score_enet_te_test_mse,\n",
    "                       \n",
    "                       score_enet_pe_train,score_enet_pe_test,\n",
    "                       score_enet_pe_train_mse,score_enet_pe_test_mse,\n",
    "                       \n",
    "                       score_xgb_te_train,score_xgb_te_test,\n",
    "                       score_xgb_te_train_mse,score_xgb_te_test_mse,\n",
    "                       \n",
    "                       score_xgb_pe_train,score_xgb_pe_test,\n",
    "                       score_xgb_pe_train_mse,score_xgb_pe_test_mse,\n",
    "                       \n",
    "                       # Shape\n",
    "                       df.shape,\n",
    "                       \n",
    "                       # params\n",
    "                       enet_te_params,\n",
    "                       enet_pe_params,\n",
    "                       \n",
    "                       # Time\n",
    "                       elapsed_time_mins(tic,time.time())])\n",
    "    \n",
    "    \n",
    "resultados = pd.DataFrame(resultados,columns=columns)\n",
    "resultados.to_csv('./results_regression/resultados.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack simplified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
