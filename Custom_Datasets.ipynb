{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:25.819817Z",
     "start_time": "2020-06-11T08:02:25.806030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.729451Z",
     "start_time": "2020-06-11T08:02:25.822725Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pmlb import fetch_data,regression_dataset_names\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sktools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.742419Z",
     "start_time": "2020-06-11T08:02:27.732448Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    '''\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        #print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        #print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "def elapsed_time_mins (time1,time2):\n",
    "    elapsed = np.round(np.abs(time1-time2)/60,decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "\n",
    "def fit_pipe(pipe,pipe_grid,X,y,subsample=False,n_max=20_000,best_params=True):\n",
    "    \n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "    \n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(pipe, param_grid=pipe_grid, n_jobs = n_jobs, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    pipe_cv.fit(X,y)\n",
    "    \n",
    "    best_estimator = pipe_cv.best_estimator_.fit( X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "    \n",
    "    return best_estimator,grid_results,pipe_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.764484Z",
     "start_time": "2020-06-11T08:02:27.754560Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:11.521898Z",
     "start_time": "2020-06-11T08:02:08.959333Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/stackoverflow.csv')\n",
    "\n",
    "d.ConvertedSalary = pd.to_numeric(d.ConvertedSalary,errors='coerce')\n",
    "\n",
    "d = d[d.ConvertedSalary.isna()!=True]\n",
    "\n",
    "\n",
    "\n",
    "d.to_csv('data/stackoverflow.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.781607Z",
     "start_time": "2020-06-11T08:02:27.777419Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    'data/house_kaggle.csv',\n",
    "    'data/stackoverflow.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.791785Z",
     "start_time": "2020-06-11T08:02:27.784483Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    ['Id'],\n",
    "    ['Respondent','Salary']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.798576Z",
     "start_time": "2020-06-11T08:02:27.795131Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    ['MSSubClass','MSZoning','LotShape','LandContour','Utilities','LotConfig','Neighborhood','BldgType','HouseStyle','YearBuilt','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','MasVnrType','Heating','HeatingQC'],\n",
    "    ['Country','Employment','FormalEducation','UndergradMajor','CompanySize','DevType','YearsCoding','LanguageWorkedWith','LanguageDesireNextYear','RaceEthnicity']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.805986Z",
     "start_time": "2020-06-11T08:02:27.801022Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    ['SalePrice'],\n",
    "    ['ConvertedSalary']\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:27.815043Z",
     "start_time": "2020-06-11T08:02:27.810953Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic=time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns =['NameDataset',\n",
    "          # Scores\n",
    "          'enet_te_train_mae','enet_te_test_mae',\n",
    "          'enet_te_train_mse','enet_te_test_mse',\n",
    "          \n",
    "          'enet_pe_train_mae','enet_pe_test_mae',\n",
    "          'enet_pe_train_mse','enet_pe_test_mse',\n",
    "          \n",
    "          'xgb_te_train_mae','xgb_te_test_mae',\n",
    "          'xgb_te_train_mse','xgb_te_test_mse',\n",
    "          \n",
    "          'xgb_pe_train_mae','xgb_pe_test_mae',\n",
    "          'xgb_pe_train_mse','xgb_pe_test_mse',\n",
    "          \n",
    "          \n",
    "          'size',\n",
    "          \n",
    "          # Params\n",
    "          'enet_te_best_params','enet_pe_best_params',\n",
    "          # Time\n",
    "          'time_train_m']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:05:35.340984Z",
     "start_time": "2020-06-11T08:02:27.818266Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "|   Data        |  Model        |      Train         |       Test         |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "| data/house    |   enet_te     |     19913.07752        |      28497.79219       |\n",
      "| data/house    |   enet_pe     |     20789.79583        |      28081.39420       |\n",
      "| data/house    |   xgb_te     |     7993.95809        |      26006.88782       |\n",
      "| data/house    |   xgb_pe     |     8291.61565        |      28063.79100       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "| data/stack    |   enet_te     |     73973.73198        |      76926.43126       |\n",
      "| data/stack    |   enet_pe     |     45679.04494        |      63967.78923       |\n",
      "| data/stack    |   xgb_te     |     44344.95849        |      74524.76223       |\n",
      "| data/stack    |   xgb_pe     |     23041.81891        |      67886.65787       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "|-----------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('|   Data        |  Model        |      Train         |       Test         |')\n",
    "print('|---------------|---------------|--------------------|--------------------|')\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    df = df.sample(frac=0.2)\n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=drop[i])\n",
    "    \n",
    "    # Fillna\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    # if its just NaNs\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(df.drop(columns=target[i]), df[target[i]])\n",
    "        \n",
    "    # Elastic Net + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = TargetEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {}\n",
    "    \n",
    "    # Train model\n",
    "    enet_te,grid_results,enet_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "    \n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   enet_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][:10],score_enet_te_train,score_enet_te_test))\n",
    "\n",
    "    \n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[0,1,100],\n",
    "        \"pe__percentile\":[25,50,75],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    enet_pe,grid_results,enet_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    print('| {0:}    |   enet_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][:10],score_enet_pe_train,score_enet_pe_test))\n",
    "    \n",
    "         \n",
    "    # xgb + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    te = TargetEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {}\n",
    "    \n",
    "    # Train model\n",
    "    xgb_te,grid_results,xgb_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   xgb_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][:10],score_xgb_te_train,score_xgb_te_test))\n",
    "\n",
    "    # xgb + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[0,1,100],\n",
    "        \"pe__percentile\":[25,50,75],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    xgb_pe,grid_results,xgb_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    print('| {0:}    |   xgb_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][:10],score_xgb_pe_train,score_xgb_pe_test))\n",
    "\n",
    "    # Add Results\n",
    "    resultados.append([data[i].split('/')[1],\n",
    "                       #Scores\n",
    "                       score_enet_te_train,score_enet_te_test,\n",
    "                       score_enet_te_train_mse,score_enet_te_test_mse,\n",
    "                       \n",
    "                       score_enet_pe_train,score_enet_pe_test,\n",
    "                       score_enet_pe_train_mse,score_enet_pe_test_mse,\n",
    "                       \n",
    "                       score_xgb_te_train,score_xgb_te_test,\n",
    "                       score_xgb_te_train_mse,score_xgb_te_test_mse,\n",
    "                       \n",
    "                       score_xgb_pe_train,score_xgb_pe_test,\n",
    "                       score_xgb_pe_train_mse,score_xgb_pe_test_mse,\n",
    "                       \n",
    "                       # Shape\n",
    "                       df.shape,\n",
    "                       \n",
    "                       # params\n",
    "                       enet_te_params,\n",
    "                       enet_pe_params,\n",
    "                       \n",
    "                       # Time\n",
    "                       elapsed_time_mins(tic,time.time())])\n",
    "    print('|---------------|---------------|--------------------|--------------------|')\n",
    "\n",
    "    \n",
    "print('|-----------------------------------------------------------------|')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
