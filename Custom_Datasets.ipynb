{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:16.108052Z",
     "start_time": "2020-06-24T07:40:16.089502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.017287Z",
     "start_time": "2020-06-24T07:40:16.112132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from pmlb import fetch_data,regression_dataset_names\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sktools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.028058Z",
     "start_time": "2020-06-24T07:40:18.020347Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    '''\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        #print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        #print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "def elapsed_time_mins (time1,time2):\n",
    "    elapsed = np.round(np.abs(time1-time2)/60,decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "\n",
    "def fit_pipe(pipe,pipe_grid,X,y,subsample=False,n_max=20_000,best_params=True):\n",
    "    \n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "    \n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(pipe, param_grid=pipe_grid, n_jobs = n_jobs, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    pipe_cv.fit(X,y)\n",
    "    \n",
    "    best_estimator = pipe_cv.best_estimator_.fit( X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "    \n",
    "    return best_estimator,grid_results,pipe_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:11.521898Z",
     "start_time": "2020-06-11T08:02:08.959333Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/stackoverflow.csv')\n",
    "\n",
    "d.ConvertedSalary = pd.to_numeric(d.ConvertedSalary,errors='coerce')\n",
    "\n",
    "d = d[d.ConvertedSalary.isna()!=True]\n",
    "\n",
    "\n",
    "\n",
    "d.to_csv('data/stackoverflow.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.042133Z",
     "start_time": "2020-06-24T07:40:18.030927Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    'data/house_kaggle.csv',\n",
    "    'data/stackoverflow.csv',\n",
    "    'data/ks.csv',\n",
    "    'data/medical_payments_sample.csv',\n",
    "    'data/cauchy.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.063271Z",
     "start_time": "2020-06-24T07:40:18.050527Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    ['Id','BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2','BsmtFinSF2', 'BsmtUnfSF','LowQualFinSF','FullBath','HalfBath'],\n",
    "    ['Respondent','Salary'],\n",
    "    [],\n",
    "    ['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name','Number_of_Payments_Included_in_Total_Amount'],\n",
    "    []\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.076256Z",
     "start_time": "2020-06-24T07:40:18.069306Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    ['MSSubClass','MSZoning','LotShape','LandContour','Utilities','LotConfig','Neighborhood','BldgType','HouseStyle','YearBuilt','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','MasVnrType','Heating','HeatingQC'],\n",
    "    ['Country','Employment','FormalEducation','UndergradMajor','CompanySize','DevType','YearsCoding','LanguageWorkedWith','LanguageDesireNextYear','RaceEthnicity'],\n",
    "    ['category', 'main_category', 'currency','state','country'],\n",
    "    \n",
    "    ['Recipient_City', 'Recipient_State', 'Recipient_Zip_Code','Recipient_Country', 'Physician_Primary_Type',\n",
    "       'Physician_License_State_code1',\n",
    "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "       'Form_of_Payment_or_Transfer_of_Value','Nature_of_Payment_or_Transfer_of_Value'],\n",
    "    \n",
    "    ['value_1', 'value_2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.087861Z",
     "start_time": "2020-06-24T07:40:18.080974Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    ['SalePrice'],\n",
    "    ['ConvertedSalary'],\n",
    "    ['goal'],\n",
    "    ['Total_Amount_of_Payment_USDollars'],\n",
    "    ['target']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:18.100327Z",
     "start_time": "2020-06-24T07:40:18.093301Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic=time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns =['NameDataset',\n",
    "          # Scores\n",
    "          'enet_te_train_mae','enet_te_test_mae',\n",
    "          'enet_te_train_mse','enet_te_test_mse',\n",
    "          \n",
    "          'enet_pe_train_mae','enet_pe_test_mae',\n",
    "          'enet_pe_train_mse','enet_pe_test_mse',\n",
    "          \n",
    "          'xgb_te_train_mae','xgb_te_test_mae',\n",
    "          'xgb_te_train_mse','xgb_te_test_mse',\n",
    "          \n",
    "          'xgb_pe_train_mae','xgb_pe_test_mae',\n",
    "          'xgb_pe_train_mse','xgb_pe_test_mse',\n",
    "          \n",
    "          \n",
    "          'size',\n",
    "          \n",
    "          # Params\n",
    "          'enet_te_best_params','enet_pe_best_params',\n",
    "          # Time\n",
    "          'time_train_m']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T07:40:19.910962Z",
     "start_time": "2020-06-24T07:40:18.104900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "|   Data        |  Model        |      Train         |       Test         |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(15, 69)\n",
      "| house    |   enet_te     |     3377.61543        |      36970.75232       |\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7e6239a1a9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mscaler\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msktools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPercentileEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcols_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'm'"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('|   Data        |  Model        |      Train         |       Test         |')\n",
    "print('|---------------|---------------|--------------------|--------------------|')\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    df = df.sample(frac=0.01)\n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=drop[i])\n",
    "    \n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(df.drop(columns=target[i]), df[target[i]])\n",
    "   \n",
    "\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    enet_te,enet_te_grid_results,enet_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "    \n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   enet_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_enet_te_train,score_enet_te_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__percentile\":[50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    enet_pe,enet_pe_grid_results,enet_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    print('| {0:}    |   enet_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_enet_pe_train,score_enet_pe_test))\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # xgb + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = QuantileRegression()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    xgb_te,xgb_te_grid_results,xgb_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   xgb_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_xgb_te_train,score_xgb_te_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # xgb + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = QuantileRegression()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__percentile\":[50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    xgb_pe,xgb_pe_grid_results,xgb_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    print('| {0:}    |   xgb_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_xgb_pe_train,score_xgb_pe_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_pe_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgb_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgbt_pe_grid_results',data[i][5:10]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add Results\n",
    "    resultados.append([data[i].split('/')[1],\n",
    "                       #Scores\n",
    "                       score_enet_te_train,score_enet_te_test,\n",
    "                       score_enet_te_train_mse,score_enet_te_test_mse,\n",
    "                       \n",
    "                       score_enet_pe_train,score_enet_pe_test,\n",
    "                       score_enet_pe_train_mse,score_enet_pe_test_mse,\n",
    "                       \n",
    "                       score_xgb_te_train,score_xgb_te_test,\n",
    "                       score_xgb_te_train_mse,score_xgb_te_test_mse,\n",
    "                       \n",
    "                       score_xgb_pe_train,score_xgb_pe_test,\n",
    "                       score_xgb_pe_train_mse,score_xgb_pe_test_mse,\n",
    "                       \n",
    "                       # Shape\n",
    "                       df.shape,\n",
    "                       \n",
    "                       # params\n",
    "                       enet_te_params,\n",
    "                       enet_pe_params,\n",
    "                       \n",
    "                       # Time\n",
    "                       elapsed_time_mins(tic,time.time())])\n",
    "    print('|---------------|---------------|--------------------|--------------------|')\n",
    "    \n",
    "    \n",
    "resultados = pd.DataFrame(resultados,columns=columns)\n",
    "resultados.to_csv('./results_regression/resultados.csv',index=False)\n",
    "\n",
    "    \n",
    "print('|-----------------------------------------------------------------|')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack simplified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
