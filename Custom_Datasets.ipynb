{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:43.375861Z",
     "start_time": "2020-06-17T16:13:43.365128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension('collapsible_headings/main')\n",
       "utils.load_extension('hide_input/main')\n",
       "utils.load_extension('autosavetime/main')\n",
       "utils.load_extension('execute_time/ExecuteTime')\n",
       "utils.load_extension('code_prettify/code_prettify')\n",
       "utils.load_extension('scroll_down/main')\n",
       "utils.load_extension('jupyter-js-widgets/extension')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension('collapsible_headings/main')\n",
    "utils.load_extension('hide_input/main')\n",
    "utils.load_extension('autosavetime/main')\n",
    "utils.load_extension('execute_time/ExecuteTime')\n",
    "utils.load_extension('code_prettify/code_prettify')\n",
    "utils.load_extension('scroll_down/main')\n",
    "utils.load_extension('jupyter-js-widgets/extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.650685Z",
     "start_time": "2020-06-17T16:13:43.378441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from pmlb import fetch_data,regression_dataset_names\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.844257Z",
     "start_time": "2020-06-17T16:13:44.660536Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "class QuantileRegression():\n",
    "    \"\"\"Quantile regression wrapper\n",
    "\n",
    "    It can work on sklearn pipelines\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> from sktools import QuantileRegression\n",
    "    >>> from sklearn.datasets import load_boston\n",
    "    >>> boston = load_boston()['data']\n",
    "    >>> y = load_boston()['target']\n",
    "    >>> qr = QuantileRegression(quantile=0.9)\n",
    "    >>> qr.fit(boston, y)\n",
    "    >>> qr.predict(boston)[0:5].round(2)\n",
    "    array([34.87, 28.98, 34.86, 32.67, 32.52])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, quantile=0.5, add_intercept=True):\n",
    "\n",
    "        self.quantile = quantile\n",
    "        self.add_intercept = add_intercept\n",
    "        self.regressor = None\n",
    "        self.regressor_fit = None\n",
    "\n",
    "    def preprocess(self, X):\n",
    "\n",
    "        X = X.copy()\n",
    "        if self.add_intercept:\n",
    "            X = sm.add_constant(X)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X = self.preprocess(X)\n",
    "\n",
    "        self.regressor = QuantReg(y, X)\n",
    "        self.regressor_fit = self.regressor.fit(q=self.quantile)\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "\n",
    "        X = self.preprocess(X)\n",
    "\n",
    "        return self.regressor_fit.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.853711Z",
     "start_time": "2020-06-17T16:13:44.846335Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    '''\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        #print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        #print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "def elapsed_time_mins (time1,time2):\n",
    "    elapsed = np.round(np.abs(time1-time2)/60,decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "\n",
    "def fit_pipe(pipe,pipe_grid,X,y,subsample=False,n_max=20_000,best_params=True):\n",
    "    \n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "    \n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(pipe, param_grid=pipe_grid, n_jobs = n_jobs, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    pipe_cv.fit(X,y)\n",
    "    \n",
    "    best_estimator = pipe_cv.best_estimator_.fit( X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "    \n",
    "    return best_estimator,grid_results,pipe_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.863108Z",
     "start_time": "2020-06-17T16:13:44.856187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/Desktop/sktools\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.888410Z",
     "start_time": "2020-06-17T16:13:44.882262Z"
    }
   },
   "outputs": [],
   "source": [
    "import sktools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.898374Z",
     "start_time": "2020-06-17T16:13:44.890643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cmougan/Desktop/sktools/CARLOS_TEST\n"
     ]
    }
   ],
   "source": [
    "cd CARLOS_TEST/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-11T08:02:11.521898Z",
     "start_time": "2020-06-11T08:02:08.959333Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/stackoverflow.csv')\n",
    "\n",
    "d.ConvertedSalary = pd.to_numeric(d.ConvertedSalary,errors='coerce')\n",
    "\n",
    "d = d[d.ConvertedSalary.isna()!=True]\n",
    "\n",
    "\n",
    "\n",
    "d.to_csv('data/stackoverflow.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.909368Z",
     "start_time": "2020-06-17T16:13:44.905676Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    #'data/house_kaggle.csv',\n",
    "    'data/stackoverflow.csv',\n",
    "    'data/ks.csv',\n",
    "    'data/medical_payments_sample.csv',\n",
    "    'data/cauchy.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.916266Z",
     "start_time": "2020-06-17T16:13:44.911660Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    #['Id','BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2','BsmtFinSF2', 'BsmtUnfSF','LowQualFinSF','FullBath','HalfBath'],\n",
    "    ['Respondent','Salary'],\n",
    "    [],\n",
    "    ['Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name','Number_of_Payments_Included_in_Total_Amount'],\n",
    "    []\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.932629Z",
     "start_time": "2020-06-17T16:13:44.919694Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    #['MSSubClass','MSZoning','LotShape','LandContour','Utilities','LotConfig','Neighborhood','BldgType','HouseStyle','YearBuilt','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','ExterQual','MasVnrType','Heating','HeatingQC'],\n",
    "    ['Country','Employment','FormalEducation','UndergradMajor','CompanySize','DevType','YearsCoding','LanguageWorkedWith','LanguageDesireNextYear','RaceEthnicity'],\n",
    "    ['category', 'main_category', 'currency','state','country'],\n",
    "    \n",
    "    ['Recipient_City', 'Recipient_State', 'Recipient_Zip_Code','Recipient_Country', 'Physician_Primary_Type',\n",
    "       'Physician_License_State_code1',\n",
    "       'Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name',\n",
    "       'Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country',\n",
    "       'Form_of_Payment_or_Transfer_of_Value','Nature_of_Payment_or_Transfer_of_Value'],\n",
    "    \n",
    "    ['value_1', 'value_2']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.964569Z",
     "start_time": "2020-06-17T16:13:44.957313Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    #['SalePrice'],\n",
    "    ['ConvertedSalary'],\n",
    "    ['goal'],\n",
    "    ['Total_Amount_of_Payment_USDollars'],\n",
    "    ['target']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:13:44.982837Z",
     "start_time": "2020-06-17T16:13:44.976593Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic=time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns =['NameDataset',\n",
    "          # Scores\n",
    "          'enet_te_train_mae','enet_te_test_mae',\n",
    "          'enet_te_train_mse','enet_te_test_mse',\n",
    "          \n",
    "          'enet_pe_train_mae','enet_pe_test_mae',\n",
    "          'enet_pe_train_mse','enet_pe_test_mse',\n",
    "          \n",
    "          'xgb_te_train_mae','xgb_te_test_mae',\n",
    "          'xgb_te_train_mse','xgb_te_test_mse',\n",
    "          \n",
    "          'xgb_pe_train_mae','xgb_pe_test_mae',\n",
    "          'xgb_pe_train_mse','xgb_pe_test_mse',\n",
    "          \n",
    "          \n",
    "          'size',\n",
    "          \n",
    "          # Params\n",
    "          'enet_te_best_params','enet_pe_best_params',\n",
    "          # Time\n",
    "          'time_train_m']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T16:31:20.042599Z",
     "start_time": "2020-06-17T16:13:44.986487Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "|   Data        |  Model        |      Train         |       Test         |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(47702, 127)\n",
      "| stack    |   enet_te     |     54935.98468        |      81106.17699       |\n",
      "| stack    |   enet_pe     |     50803.95641        |      71636.26059       |\n",
      "| stack    |   xgb_te     |     49967.20869        |      65892.01958       |\n",
      "| stack    |   xgb_pe     |     42443.98869        |      69250.69490       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(319328, 8)\n",
      "| ks.cs    |   enet_te     |     70047.03453        |      67542.62090       |\n",
      "| ks.cs    |   enet_pe     |     68201.83079        |      65607.21197       |\n",
      "| ks.cs    |   xgb_te     |     44882.25341        |      41962.04759       |\n",
      "| ks.cs    |   xgb_pe     |     44557.37694        |      41676.77787       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(1081563, 11)\n",
      "| medic    |   enet_te     |     558.91762        |      648.38104       |\n",
      "| medic    |   enet_pe     |     303.24125        |      393.14684       |\n",
      "| medic    |   xgb_te     |     225.10338        |      309.73412       |\n",
      "| medic    |   xgb_pe     |     204.55365        |      291.57271       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(100000, 3)\n",
      "| cauch    |   enet_te     |     23.67518        |      21.53573       |\n",
      "| cauch    |   enet_pe     |     21.95364        |      19.81504       |\n",
      "| cauch    |   xgb_te     |     21.79700        |      19.68620       |\n",
      "| cauch    |   xgb_pe     |     20.01368        |      17.87961       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "|-----------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('|   Data        |  Model        |      Train         |       Test         |')\n",
    "print('|---------------|---------------|--------------------|--------------------|')\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    \n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    #df = df.sample(frac=0.01)\n",
    "    \n",
    "    # Drop columns \n",
    "    df = df.drop(columns=drop[i])\n",
    "    \n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0,inplace=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(df.drop(columns=target[i]), df[target[i]])\n",
    "   \n",
    "\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    enet_te,enet_te_grid_results,enet_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "    \n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   enet_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_enet_te_train,score_enet_te_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__percentile\":[50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    enet_pe,enet_pe_grid_results,enet_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "    \n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    print('| {0:}    |   enet_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_enet_pe_train,score_enet_pe_test))\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # xgb + target encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = QuantileRegression()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('te',te),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = {\n",
    "        \"te__m\":[1],\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Train model\n",
    "    xgb_te,xgb_te_grid_results,xgb_te_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "    \n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print('| {0:}    |   xgb_te     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_xgb_te_train,score_xgb_te_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # xgb + percentile encoding\n",
    "    scaler  = sklearn.preprocessing.StandardScaler()\n",
    "    clf = QuantileRegression()\n",
    "    pe = sktools.PercentileEncoder(cols= cols_enc[i],percentile=50,m=0)\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "        \n",
    "\n",
    "    pipe = Pipeline([\n",
    "            ('pe',pe),\n",
    "            ('selector', TypeSelector(np.number)), # Selects Numerical Columns only\n",
    "            ('var',var),\n",
    "            ('scaler', scaler),\n",
    "            ('clf',clf )])\n",
    "        \n",
    "    pipe_grid = { \n",
    "        \"pe__m\":[1],\n",
    "        \"pe__percentile\":[50],\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    xgb_pe,xgb_pe_grid_results,xgb_pe_params = fit_pipe(pipe,pipe_grid,X_tr,y_tr)\n",
    "\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "    \n",
    "    print('| {0:}    |   xgb_pe     |     {1:.5f}        |      {2:.5f}       |'.format(data[i][5:10],score_xgb_pe_train,score_xgb_pe_test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('enet_pe_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgb_te_grid_results',data[i][5:10]))\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv('./results_regression/grid_results/{}_{}.csv'.format('xgbt_pe_grid_results',data[i][5:10]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Add Results\n",
    "    resultados.append([data[i].split('/')[1],\n",
    "                       #Scores\n",
    "                       score_enet_te_train,score_enet_te_test,\n",
    "                       score_enet_te_train_mse,score_enet_te_test_mse,\n",
    "                       \n",
    "                       score_enet_pe_train,score_enet_pe_test,\n",
    "                       score_enet_pe_train_mse,score_enet_pe_test_mse,\n",
    "                       \n",
    "                       score_xgb_te_train,score_xgb_te_test,\n",
    "                       score_xgb_te_train_mse,score_xgb_te_test_mse,\n",
    "                       \n",
    "                       score_xgb_pe_train,score_xgb_pe_test,\n",
    "                       score_xgb_pe_train_mse,score_xgb_pe_test_mse,\n",
    "                       \n",
    "                       # Shape\n",
    "                       df.shape,\n",
    "                       \n",
    "                       # params\n",
    "                       enet_te_params,\n",
    "                       enet_pe_params,\n",
    "                       \n",
    "                       # Time\n",
    "                       elapsed_time_mins(tic,time.time())])\n",
    "    print('|---------------|---------------|--------------------|--------------------|')\n",
    "    \n",
    "    \n",
    "resultados = pd.DataFrame(resultados,columns=columns)\n",
    "resultados.to_csv('./results_regression/resultados.csv',index=False)\n",
    "\n",
    "    \n",
    "print('|-----------------------------------------------------------------|')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack simplified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
