{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:16:39.271608Z",
     "start_time": "2020-06-01T15:16:39.268672Z"
    }
   },
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:02:41.097413Z",
     "start_time": "2020-06-28T18:02:41.080520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "utils.load_extension(\"collapsible_headings/main\")\n",
       "utils.load_extension(\"hide_input/main\")\n",
       "utils.load_extension(\"autosavetime/main\")\n",
       "utils.load_extension(\"execute_time/ExecuteTime\")\n",
       "utils.load_extension(\"code_prettify/code_prettify\")\n",
       "utils.load_extension(\"scroll_down/main\")\n",
       "utils.load_extension(\"jupyter-js-widgets/extension\")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "utils.load_extension(\"collapsible_headings/main\")\n",
    "utils.load_extension(\"hide_input/main\")\n",
    "utils.load_extension(\"autosavetime/main\")\n",
    "utils.load_extension(\"execute_time/ExecuteTime\")\n",
    "utils.load_extension(\"code_prettify/code_prettify\")\n",
    "utils.load_extension(\"scroll_down/main\")\n",
    "utils.load_extension(\"jupyter-js-widgets/extension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:07:55.014380Z",
     "start_time": "2020-06-28T18:07:55.008663Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "import sklearn\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"max_columns\", None)\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "from pmlb import fetch_data, regression_dataset_names\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sktools\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:07:28.566056Z",
     "start_time": "2020-06-28T18:07:28.557566Z"
    }
   },
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer that filters a type of columns of a given data frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        # print(\"Type Selector out shape {}\".format(X.select_dtypes(include=[self.dtype]).shape))\n",
    "        # print(X.select_dtypes(include=[self.dtype]).dtypes)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "\n",
    "\n",
    "def elapsed_time_mins(time1, time2):\n",
    "    elapsed = np.round(np.abs(time1 - time2) / 60, decimals=2)\n",
    "\n",
    "    return elapsed\n",
    "\n",
    "\n",
    "def fit_pipe(pipe, pipe_grid, X, y, subsample=False, n_max=20_000, best_params=True):\n",
    "\n",
    "    if subsample:\n",
    "        X = X[0:n_max]\n",
    "        y = y[0:n_max]\n",
    "\n",
    "    # Instantiate the grid\n",
    "    pipe_cv = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=pipe_grid,\n",
    "        n_jobs=n_jobs,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "    )\n",
    "\n",
    "    pipe_cv.fit(X, y)\n",
    "\n",
    "    best_estimator = pipe_cv.best_estimator_.fit(X_tr, y_tr)\n",
    "    grid_results = pd.DataFrame(pipe_cv.cv_results_)\n",
    "\n",
    "    return best_estimator, grid_results, pipe_cv.best_params_\n",
    "\n",
    "\n",
    "def compare_results(grid_1_res, grid_2_res):\n",
    "\n",
    "    all_results = grid_1_res.melt().merge(\n",
    "        grid_2_res.melt(), on=\"variable\", suffixes=(\"_te\", \"_pe\")\n",
    "    )\n",
    "\n",
    "    all_results = all_results[all_results[\"variable\"].str.contains(\"split\")]\n",
    "\n",
    "    test_results = wilcoxon(\n",
    "        all_results.value_pe, all_results.value_te, alternative=\"greater\"\n",
    "    )\n",
    "\n",
    "    return test_results.pvalue.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:01.864123Z",
     "start_time": "2020-06-28T18:04:01.857239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check directories\n",
    "\n",
    "\n",
    "directory = './results_regression/pickle'\n",
    "if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "directory = './results_regression/grid_results/'\n",
    "if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "directory = './results_regression/partial/'\n",
    "if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "directory = './results_regression/datasets/'\n",
    "if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T17:23:57.552700Z",
     "start_time": "2020-06-28T17:23:57.060545Z"
    }
   },
   "source": [
    "d = pd.read_csv('data/so2019.csv')\n",
    "\n",
    "\n",
    "\n",
    "for col in d.columns:\n",
    "    if len(d[col].unique()) < 10:\n",
    "        print(col)\n",
    "        d.drop(col,inplace=True,axis=1)\n",
    "\n",
    "\n",
    "d.to_csv('data/so2019.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:02.488759Z",
     "start_time": "2020-06-28T18:04:02.485283Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    'data/house_kaggle.csv',\n",
    "    'data/stackoverflow.csv',\n",
    "    'data/so2019.csv',\n",
    "    'data/ks.csv',\n",
    "    'data/medical_payments_sample.csv',\n",
    "    'data/cauchy.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:02.659717Z",
     "start_time": "2020-06-28T18:04:02.656655Z"
    }
   },
   "outputs": [],
   "source": [
    "drop = [\n",
    "    [\n",
    "        \"Id\",\n",
    "        \"BsmtQual\",\n",
    "        \"BsmtCond\",\n",
    "        \"BsmtExposure\",\n",
    "        \"BsmtFinType1\",\n",
    "        \"BsmtFinSF1\",\n",
    "        \"BsmtFinType2\",\n",
    "        \"BsmtFinSF2\",\n",
    "        \"BsmtUnfSF\",\n",
    "        \"LowQualFinSF\",\n",
    "        \"FullBath\",\n",
    "        \"HalfBath\",\n",
    "    ],\n",
    "    [\"Respondent\", \"Salary\"],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:02.846626Z",
     "start_time": "2020-06-28T18:04:02.842585Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_enc = [\n",
    "    [\n",
    "        \"MSSubClass\",\n",
    "        \"MSZoning\",\n",
    "        \"LotShape\",\n",
    "        \"LandContour\",\n",
    "        \"Utilities\",\n",
    "        \"LotConfig\",\n",
    "        \"Neighborhood\",\n",
    "        \"BldgType\",\n",
    "        \"HouseStyle\",\n",
    "        \"YearBuilt\",\n",
    "        \"RoofStyle\",\n",
    "        \"RoofMatl\",\n",
    "        \"Exterior1st\",\n",
    "        \"Exterior2nd\",\n",
    "        \"ExterQual\",\n",
    "        \"MasVnrType\",\n",
    "        \"Heating\",\n",
    "        \"HeatingQC\",\n",
    "    ],\n",
    "    [\n",
    "        \"Country\",\n",
    "        \"Employment\",\n",
    "        \"FormalEducation\",\n",
    "        \"UndergradMajor\",\n",
    "        \"CompanySize\",\n",
    "        \"DevType\",\n",
    "        \"YearsCoding\",\n",
    "        \"LanguageWorkedWith\",\n",
    "        \"LanguageDesireNextYear\",\n",
    "        \"RaceEthnicity\",\n",
    "    ],\n",
    "    [\"yearscode\", \"country\"],\n",
    "    [\"category\", \"main_category\", \"currency\", \"state\", \"country\"],\n",
    "    [\n",
    "        \"Recipient_City\",\n",
    "        \"Recipient_State\",\n",
    "        \"Recipient_Zip_Code\",\n",
    "        \"Recipient_Country\",\n",
    "        \"Physician_Primary_Type\",\n",
    "        \"Physician_License_State_code1\",\n",
    "        \"Submitting_Applicable_Manufacturer_or_Applicable_GPO_Name\",\n",
    "        \"Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Country\",\n",
    "        \"Form_of_Payment_or_Transfer_of_Value\",\n",
    "        \"Nature_of_Payment_or_Transfer_of_Value\",\n",
    "    ],\n",
    "    [\"value_1\", \"value_2\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:03.042665Z",
     "start_time": "2020-06-28T18:04:03.039496Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    ['SalePrice'],\n",
    "    ['ConvertedSalary'],\n",
    "    ['convertedcomp'],\n",
    "    ['goal'],\n",
    "    ['Total_Amount_of_Payment_USDollars'],\n",
    "    ['target']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T15:30:39.185710Z",
     "start_time": "2020-06-01T15:30:39.181882Z"
    }
   },
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:03.455415Z",
     "start_time": "2020-06-28T18:04:03.443750Z"
    }
   },
   "outputs": [],
   "source": [
    "n_jobs = 1\n",
    "float_eltype = np.float32\n",
    "resultados = []\n",
    "tic = time.time()\n",
    "\n",
    "n_max = 20_000\n",
    "cv = 4\n",
    "filter_size = 2_000\n",
    "columns = [\n",
    "    \"NameDataset\",\n",
    "    # Scores\n",
    "    \"enet_te_train_mae\",\n",
    "    \"enet_te_test_mae\",\n",
    "    \"enet_te_train_mse\",\n",
    "    \"enet_te_test_mse\",\n",
    "    \"enet_pe_train_mae\",\n",
    "    \"enet_pe_test_mae\",\n",
    "    \"enet_pe_train_mse\",\n",
    "    \"enet_pe_test_mse\",\n",
    "    \"xgb_te_train_mae\",\n",
    "    \"xgb_te_test_mae\",\n",
    "    \"xgb_te_train_mse\",\n",
    "    \"xgb_te_test_mse\",\n",
    "    \"xgb_pe_train_mae\",\n",
    "    \"xgb_pe_test_mae\",\n",
    "    \"xgb_pe_train_mse\",\n",
    "    \"xgb_pe_test_mse\",\n",
    "    \"size\",\n",
    "    # Params\n",
    "    \"enet_te_best_params\",\n",
    "    \"enet_pe_best_params\",\n",
    "    # Time\n",
    "    \"time_train_m\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:04:34.226014Z",
     "start_time": "2020-06-28T18:04:03.642461Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "|   Data        |  Model        |      Train         |       Test         |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(15, 69)\n",
      "| house    |   enet_te     |     1762.37474        |      15546.73815       |\n",
      "| house    |   enet_pe     |     1675.82631        |      15392.36709       |\n",
      "| house    |   xgb_te     |     3.67707        |      37486.82149       |\n",
      "| house    |   xgb_pe     |     3.07396        |      35936.23373       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(477, 127)\n",
      "| stack    |   enet_te     |     41082.87517        |      66877.76257       |\n",
      "| stack    |   enet_pe     |     33911.31431        |      59649.18186       |\n",
      "| stack    |   xgb_te     |     40882.03929        |      68145.95337       |\n",
      "| stack    |   xgb_pe     |     34994.02311        |      69264.85173       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(506, 5)\n",
      "| so201    |   enet_te     |     24117.64119        |      28469.38204       |\n",
      "| so201    |   enet_pe     |     24453.41217        |      28131.99521       |\n",
      "| so201    |   xgb_te     |     22435.46982        |      27687.68108       |\n",
      "| so201    |   xgb_pe     |     22717.65147        |      26966.76103       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(3193, 8)\n",
      "| ks.cs    |   enet_te     |     30718.30619        |      105692.19939       |\n",
      "| ks.cs    |   enet_pe     |     30093.37067        |      104396.79821       |\n",
      "| ks.cs    |   xgb_te     |     33682.79022        |      108693.03849       |\n",
      "| ks.cs    |   xgb_pe     |     29764.66111        |      104027.63740       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(10816, 13)\n",
      "| medic    |   enet_te     |     193.19815        |      253.84630       |\n",
      "| medic    |   enet_pe     |     131.60108        |      199.26084       |\n",
      "| medic    |   xgb_te     |     213.43564        |      270.58177       |\n",
      "| medic    |   xgb_pe     |     142.53296        |      214.53485       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "(1000, 3)\n",
      "| cauch    |   enet_te     |     12.53389        |      18.71053       |\n",
      "| cauch    |   enet_pe     |     12.41386        |      18.04858       |\n",
      "| cauch    |   xgb_te     |     11.90618        |      19.20175       |\n",
      "| cauch    |   xgb_pe     |     9.93860        |      16.39199       |\n",
      "|---------------|---------------|--------------------|--------------------|\n",
      "|-----------------------------------------------------------------|\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(\"|   Data        |  Model        |      Train         |       Test         |\")\n",
    "print(\"|---------------|---------------|--------------------|--------------------|\")\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "\n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "    df = df.sample(frac=0.01)\n",
    "\n",
    "    # Drop columns\n",
    "    df = df.drop(columns=drop[i])\n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(\n",
    "        df.drop(columns=target[i]), df[target[i]]\n",
    "    )\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"te\", te),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"te__m\": [1],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    enet_te, enet_te_grid_results, enet_te_params = fit_pipe(\n",
    "        pipe, pipe_grid, X_tr, y_tr\n",
    "    )\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print(\n",
    "        \"| {0:}    |   enet_te     |     {1:.5f}        |      {2:.5f}       |\".format(\n",
    "            data[i][5:10], score_enet_te_train, score_enet_te_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.QuantileEncoder(cols=cols_enc[i], quantile=0.50, m=0)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"pe\", pe),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"pe__m\": [1],\n",
    "        \"pe__quantile\": [0.50],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    enet_pe, enet_pe_grid_results, enet_pe_params = fit_pipe(\n",
    "        pipe, pipe_grid, X_tr, y_tr\n",
    "    )\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "\n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "    print(\n",
    "        \"| {0:}    |   enet_pe     |     {1:.5f}        |      {2:.5f}       |\".format(\n",
    "            data[i][5:10], score_enet_pe_train, score_enet_pe_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # xgb + target encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.Lasso()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"te\", te),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"var\", var),\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"te__m\": [1],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    xgb_te, xgb_te_grid_results, xgb_te_params = fit_pipe(pipe, pipe_grid, X_tr, y_tr)\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print(\n",
    "        \"| {0:}    |   xgb_te     |     {1:.5f}        |      {2:.5f}       |\".format(\n",
    "            data[i][5:10], score_xgb_te_train, score_xgb_te_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # xgb + percentile encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.Lasso()\n",
    "    pe = sktools.QuantileEncoder(cols=cols_enc[i], quantile=0.50, m=0)\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"pe\", pe),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"var\", var),\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"pe__m\": [1],\n",
    "        \"pe__quantile\": [0.50],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    xgb_pe, xgb_pe_grid_results, xgb_pe_params = fit_pipe(pipe, pipe_grid, X_tr, y_tr)\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "\n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "\n",
    "    print(\n",
    "        \"| {0:}    |   xgb_pe     |     {1:.5f}        |      {2:.5f}       |\".format(\n",
    "            data[i][5:10], score_xgb_pe_train, score_xgb_pe_test\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"enet_te_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"enet_pe_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"xgb_te_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"xgbt_pe_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add Results\n",
    "    resultados.append(\n",
    "        [\n",
    "            data[i].split(\"/\")[1],\n",
    "            # Scores\n",
    "            score_enet_te_train,\n",
    "            score_enet_te_test,\n",
    "            score_enet_te_train_mse,\n",
    "            score_enet_te_test_mse,\n",
    "            score_enet_pe_train,\n",
    "            score_enet_pe_test,\n",
    "            score_enet_pe_train_mse,\n",
    "            score_enet_pe_test_mse,\n",
    "            score_xgb_te_train,\n",
    "            score_xgb_te_test,\n",
    "            score_xgb_te_train_mse,\n",
    "            score_xgb_te_test_mse,\n",
    "            score_xgb_pe_train,\n",
    "            score_xgb_pe_test,\n",
    "            score_xgb_pe_train_mse,\n",
    "            score_xgb_pe_test_mse,\n",
    "            # Shape\n",
    "            df.shape,\n",
    "            # params\n",
    "            enet_te_params,\n",
    "            enet_pe_params,\n",
    "            # Time\n",
    "            elapsed_time_mins(tic, time.time()),\n",
    "        ]\n",
    "    )\n",
    "    print(\"|---------------|---------------|--------------------|--------------------|\")\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame(resultados, columns=columns)\n",
    "resultados.to_csv(\"./results_regression/resultados.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"|-----------------------------------------------------------------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T18:16:22.820682Z",
     "start_time": "2020-06-28T18:07:58.516333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------+----------+\n",
      "| Data   | Model   | Train   | Test   | pvalue   |\n",
      "|--------+---------+---------+--------+----------|\n",
      "+--------+---------+---------+--------+----------+\n",
      "(1460, 69)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| house | enet_te | 18702.1 | 20265.8 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| house | enet_pe | 18750.1 | 20412.8 | 0.935 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| house | xgbs_te | 5632.71 | 16961.1 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| house | xgbs_pe | 5605.76 | 16686.2 | 0.396 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(47702, 127)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| stack | enet_te | 54471.7 | 81886.5 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+---+\n",
      "| stack | enet_pe | 50666.9 | 72443.9 | 0 |\n",
      "+-------+---------+---------+---------+---+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| stack | xgbs_te | 34972.5 | 73161.5 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+------+\n",
      "| stack | xgbs_pe | 36065.6 | 71053.3 | 0.01 |\n",
      "+-------+---------+---------+---------+------+\n",
      "(50599, 5)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| so201 | enet_te | 25161.7 | 25251.6 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+-------+------+\n",
      "| so201 | enet_pe | 25176.4 | 25264 | 0.99 |\n",
      "+-------+---------+---------+-------+------+\n",
      "+-------+---------+-------+---------+-----+\n",
      "| so201 | xgbs_te | 21095 | 21878.4 | nan |\n",
      "+-------+---------+-------+---------+-----+\n",
      "+-------+---------+---------+---------+-------+\n",
      "| so201 | xgbs_pe | 21096.1 | 21841.4 | 0.002 |\n",
      "+-------+---------+---------+---------+-------+\n",
      "(100000, 8)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| ks.cs | enet_te | 76795.1 | 84577.3 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+---+\n",
      "| ks.cs | enet_pe | 73172.2 | 81121.1 | 0 |\n",
      "+-------+---------+---------+---------+---+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| ks.cs | xgbs_te | 77010.2 | 90472.5 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+------+\n",
      "| ks.cs | xgbs_pe | 77390.6 | 90389.6 | 0.17 |\n",
      "+-------+---------+---------+---------+------+\n",
      "(100000, 13)\n",
      "+-------+---------+--------+---------+-----+\n",
      "| medic | enet_te | 364.03 | 333.825 | nan |\n",
      "+-------+---------+--------+---------+-----+\n",
      "+-------+---------+---------+---------+---+\n",
      "| medic | enet_pe | 247.432 | 223.897 | 0 |\n",
      "+-------+---------+---------+---------+---+\n",
      "+-------+---------+---------+---------+-----+\n",
      "| medic | xgbs_te | 178.892 | 210.978 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+------+\n",
      "| medic | xgbs_pe | 188.774 | 210.949 | 0.17 |\n",
      "+-------+---------+---------+---------+------+\n",
      "(100000, 3)\n",
      "+-------+---------+---------+---------+-----+\n",
      "| cauch | enet_te | 23.0604 | 22.2204 | nan |\n",
      "+-------+---------+---------+---------+-----+\n",
      "+-------+---------+---------+---------+---+\n",
      "| cauch | enet_pe | 21.6476 | 20.8217 | 0 |\n",
      "+-------+---------+---------+---------+---+\n",
      "+-------+---------+---------+--------+-----+\n",
      "| cauch | xgbs_te | 24.4986 | 23.664 | nan |\n",
      "+-------+---------+---------+--------+-----+\n",
      "+-------+---------+---------+--------+---+\n",
      "| cauch | xgbs_pe | 24.4271 | 23.593 | 0 |\n",
      "+-------+---------+---------+--------+---+\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        tabular_data=[],\n",
    "        headers=[\"Data\", \"Model\", \"Train\", \"Test\", \"pvalue\"],\n",
    "        tablefmt=\"psql\",\n",
    "    )\n",
    ")\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "\n",
    "    cv = RepeatedKFold(n_repeats=3, n_splits=4, random_state=42)\n",
    "\n",
    "    # Read data\n",
    "    df = pd.read_csv(data[i])\n",
    "\n",
    "    if df.shape[0] > 100_000:\n",
    "        df = df.sample(n=100_000)\n",
    "\n",
    "    # Drop columns\n",
    "    df = df.drop(columns=drop[i])\n",
    "\n",
    "    # Fillna\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    print(df.shape)\n",
    "    # Train-Test Split\n",
    "    X_tr, X_te, y_tr, y_te = sklearn.model_selection.train_test_split(\n",
    "        df.drop(columns=target[i]), df[target[i]]\n",
    "    )\n",
    "\n",
    "    # Elastic Net + target encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"te\", te),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"te__m\": [1],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    enet_te, enet_te_grid_results, enet_te_params = fit_pipe(\n",
    "        pipe, pipe_grid, X_tr, y_tr\n",
    "    )\n",
    "\n",
    "    score_enet_te_train = mean_absolute_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test = mean_absolute_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    score_enet_te_train_mse = mean_squared_error(y_tr, enet_te.predict(X_tr))\n",
    "    score_enet_te_test_mse = mean_squared_error(y_te, enet_te.predict(X_te))\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            tabular_data=[\n",
    "                [\n",
    "                    data[i][5:10],\n",
    "                    \"enet_te\",\n",
    "                    score_enet_te_train,\n",
    "                    score_enet_te_test,\n",
    "                    np.nan,\n",
    "                ]\n",
    "            ],\n",
    "            tablefmt=\"psql\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Elastic Net + percentile encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = sklearn.linear_model.ElasticNet()\n",
    "    pe = sktools.QuantileEncoder(cols=cols_enc[i], quantile=0.50, m=0)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"pe\", pe),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"pe__m\": [1],\n",
    "        \"pe__quantile\": [0.50],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    enet_pe, enet_pe_grid_results, enet_pe_params = fit_pipe(\n",
    "        pipe, pipe_grid, X_tr, y_tr\n",
    "    )\n",
    "\n",
    "    score_enet_pe_train = mean_absolute_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test = mean_absolute_error(y_te, enet_pe.predict(X_te))\n",
    "\n",
    "    score_enet_pe_train_mse = mean_squared_error(y_tr, enet_pe.predict(X_tr))\n",
    "    score_enet_pe_test_mse = mean_squared_error(y_te, enet_pe.predict(X_te))\n",
    "\n",
    "    pvalue = compare_results(enet_te_grid_results, enet_pe_grid_results)\n",
    "    print(\n",
    "        tabulate(\n",
    "            tabular_data=[\n",
    "                [\n",
    "                    data[i][5:10],\n",
    "                    \"enet_pe\",\n",
    "                    score_enet_pe_train,\n",
    "                    score_enet_pe_test,\n",
    "                    pvalue,\n",
    "                ]\n",
    "            ],\n",
    "            tablefmt=\"psql\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # xgb + target encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    te = MEstimateEncoder(cols=cols_enc[i])\n",
    "    var = VarianceThreshold(threshold=0.1)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"te\", te),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"var\", var),\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"te__m\": [1],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    xgb_te, xgb_te_grid_results, xgb_te_params = fit_pipe(pipe, pipe_grid, X_tr, y_tr)\n",
    "\n",
    "    score_xgb_te_train = mean_absolute_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test = mean_absolute_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    score_xgb_te_train_mse = mean_squared_error(y_tr, xgb_te.predict(X_tr))\n",
    "    score_xgb_te_test_mse = mean_squared_error(y_te, xgb_te.predict(X_te))\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            tabular_data=[\n",
    "                [\n",
    "                    data[i][5:10],\n",
    "                    \"xgbs_te \",\n",
    "                    score_xgb_te_train,\n",
    "                    score_xgb_te_test,\n",
    "                    np.nan,\n",
    "                ]\n",
    "            ],\n",
    "            tablefmt=\"psql\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # xgb + percentile encoding\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    clf = LGBMRegressor()\n",
    "    pe = sktools.QuantileEncoder(cols=cols_enc[i], quantile=0.5, m=0)\n",
    "    var = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            (\"pe\", pe),\n",
    "            (\"selector\", TypeSelector(np.number)),  # Selects Numerical Columns only\n",
    "            (\"var\", var),\n",
    "            (\"scaler\", scaler),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe_grid = {\n",
    "        \"pe__m\": [1],\n",
    "        \"pe__quantile\": [0.50],\n",
    "    }\n",
    "\n",
    "    # Train model\n",
    "    xgb_pe, xgb_pe_grid_results, xgb_pe_params = fit_pipe(pipe, pipe_grid, X_tr, y_tr)\n",
    "\n",
    "    score_xgb_pe_train = mean_absolute_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test = mean_absolute_error(y_te, xgb_pe.predict(X_te))\n",
    "\n",
    "    score_xgb_pe_train_mse = mean_squared_error(y_tr, xgb_pe.predict(X_tr))\n",
    "    score_xgb_pe_test_mse = mean_squared_error(y_te, xgb_pe.predict(X_te))\n",
    "\n",
    "    pvalue = compare_results(xgb_te_grid_results, xgb_pe_grid_results)\n",
    "    print(\n",
    "        tabulate(\n",
    "            tabular_data=[\n",
    "                [\n",
    "                    data[i][5:10],\n",
    "                    \"xgbs_pe\",\n",
    "                    score_xgb_pe_train,\n",
    "                    score_xgb_pe_test,\n",
    "                    pvalue,\n",
    "                ]\n",
    "            ],\n",
    "            tablefmt=\"psql\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Grid Results\n",
    "    pd.DataFrame(enet_te_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"enet_te_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(enet_pe_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"enet_pe_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(xgb_te_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"xgb_te_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "    pd.DataFrame(xgb_pe_grid_results).to_csv(\n",
    "        \"./results_regression/grid_results/{}_{}.csv\".format(\n",
    "            \"xgbt_pe_grid_results\", data[i][5:10]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add Results\n",
    "    resultados.append(\n",
    "        [\n",
    "            data[i].split(\"/\")[1],\n",
    "            # Scores\n",
    "            score_enet_te_train,\n",
    "            score_enet_te_test,\n",
    "            score_enet_te_train_mse,\n",
    "            score_enet_te_test_mse,\n",
    "            score_enet_pe_train,\n",
    "            score_enet_pe_test,\n",
    "            score_enet_pe_train_mse,\n",
    "            score_enet_pe_test_mse,\n",
    "            score_xgb_te_train,\n",
    "            score_xgb_te_test,\n",
    "            score_xgb_te_train_mse,\n",
    "            score_xgb_te_test_mse,\n",
    "            score_xgb_pe_train,\n",
    "            score_xgb_pe_test,\n",
    "            score_xgb_pe_train_mse,\n",
    "            score_xgb_pe_test_mse,\n",
    "            # Shape\n",
    "            df.shape,\n",
    "            # params\n",
    "            enet_te_params,\n",
    "            enet_pe_params,\n",
    "            # Time\n",
    "            elapsed_time_mins(tic, time.time()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "resultados = pd.DataFrame(resultados, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
